[2020-07-29 19:17:38,604] {{taskinstance.py:616}} INFO - Dependencies all met for <TaskInstance: S3_dag_test.data_collection 2020-07-27T00:00:00+00:00 [queued]>
[2020-07-29 19:17:38,633] {{taskinstance.py:616}} INFO - Dependencies all met for <TaskInstance: S3_dag_test.data_collection 2020-07-27T00:00:00+00:00 [queued]>
[2020-07-29 19:17:38,634] {{taskinstance.py:834}} INFO - 
--------------------------------------------------------------------------------
[2020-07-29 19:17:38,635] {{taskinstance.py:835}} INFO - Starting attempt 1 of 1
[2020-07-29 19:17:38,636] {{taskinstance.py:836}} INFO - 
--------------------------------------------------------------------------------
[2020-07-29 19:17:38,685] {{taskinstance.py:855}} INFO - Executing <Task(PythonOperator): data_collection> on 2020-07-27T00:00:00+00:00
[2020-07-29 19:17:38,686] {{base_task_runner.py:133}} INFO - Running: ['airflow', 'run', 'S3_dag_test', 'data_collection', '2020-07-27T00:00:00+00:00', '--job_id', '2', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/test_s3.py', '--cfg_path', '/tmp/tmpz1zx79w3']
[2020-07-29 19:17:42,425] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection [2020-07-29 19:17:42,422] {{settings.py:213}} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=1649
[2020-07-29 19:17:42,627] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection /usr/local/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
[2020-07-29 19:17:42,628] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection   """)
[2020-07-29 19:17:44,104] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection [2020-07-29 19:17:44,102] {{__init__.py:51}} INFO - Using executor LocalExecutor
[2020-07-29 19:17:45,135] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection [2020-07-29 19:17:45,131] {{dagbag.py:90}} INFO - Filling up the DagBag from /usr/local/airflow/dags/test_s3.py
[2020-07-29 19:17:45,158] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2020-07-29 19:17:45,159] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection   DeprecationWarning)
[2020-07-29 19:17:45,164] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2020-07-29 19:17:45,165] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection   DeprecationWarning)
[2020-07-29 19:17:46,356] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection [2020-07-29 19:17:46,355] {{cli.py:516}} INFO - Running <TaskInstance: S3_dag_test.data_collection 2020-07-27T00:00:00+00:00 [running]> on host 498b75d7734d
[2020-07-29 19:17:46,403] {{python_operator.py:105}} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=S3_dag_test
AIRFLOW_CTX_TASK_ID=data_collection
AIRFLOW_CTX_EXECUTION_DATE=2020-07-27T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-07-27T00:00:00+00:00
[2020-07-29 19:17:46,600] {{python_operator.py:114}} INFO - Done. Returned value was: None
[2020-07-29 19:17:48,517] {{logging_mixin.py:95}} INFO - [[34m2020-07-29 19:17:48,517[0m] {{[34mlocal_task_job.py:[0m105}} INFO[0m - Task exited with return code 0[0m
[2020-07-29 19:33:15,755] {{taskinstance.py:616}} INFO - Dependencies all met for <TaskInstance: S3_dag_test.data_collection 2020-07-27T00:00:00+00:00 [queued]>
[2020-07-29 19:33:15,776] {{taskinstance.py:616}} INFO - Dependencies all met for <TaskInstance: S3_dag_test.data_collection 2020-07-27T00:00:00+00:00 [queued]>
[2020-07-29 19:33:15,777] {{taskinstance.py:834}} INFO - 
--------------------------------------------------------------------------------
[2020-07-29 19:33:15,778] {{taskinstance.py:835}} INFO - Starting attempt 1 of 1
[2020-07-29 19:33:15,778] {{taskinstance.py:836}} INFO - 
--------------------------------------------------------------------------------
[2020-07-29 19:33:15,821] {{taskinstance.py:855}} INFO - Executing <Task(PythonOperator): data_collection> on 2020-07-27T00:00:00+00:00
[2020-07-29 19:33:15,823] {{base_task_runner.py:133}} INFO - Running: ['airflow', 'run', 'S3_dag_test', 'data_collection', '2020-07-27T00:00:00+00:00', '--job_id', '2', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/test_s3.py', '--cfg_path', '/tmp/tmpjbxnzg4l']
[2020-07-29 19:33:16,780] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection [2020-07-29 19:33:16,780] {{settings.py:213}} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=524
[2020-07-29 19:33:16,801] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection /usr/local/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
[2020-07-29 19:33:16,801] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection   """)
[2020-07-29 19:33:16,956] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection [2020-07-29 19:33:16,956] {{__init__.py:51}} INFO - Using executor LocalExecutor
[2020-07-29 19:33:17,401] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection [2020-07-29 19:33:17,401] {{dagbag.py:90}} INFO - Filling up the DagBag from /usr/local/airflow/dags/test_s3.py
[2020-07-29 19:33:17,413] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2020-07-29 19:33:17,413] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection   DeprecationWarning)
[2020-07-29 19:33:17,415] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2020-07-29 19:33:17,415] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection   DeprecationWarning)
[2020-07-29 19:33:18,136] {{base_task_runner.py:115}} INFO - Job 2: Subtask data_collection [2020-07-29 19:33:18,131] {{cli.py:516}} INFO - Running <TaskInstance: S3_dag_test.data_collection 2020-07-27T00:00:00+00:00 [running]> on host 1fdeb61556ef
[2020-07-29 19:33:18,203] {{python_operator.py:105}} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=S3_dag_test
AIRFLOW_CTX_TASK_ID=data_collection
AIRFLOW_CTX_EXECUTION_DATE=2020-07-27T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-07-27T00:00:00+00:00
[2020-07-29 19:33:18,416] {{python_operator.py:114}} INFO - Done. Returned value was: None
[2020-07-29 19:33:20,705] {{logging_mixin.py:95}} INFO - [[34m2020-07-29 19:33:20,705[0m] {{[34mlocal_task_job.py:[0m105}} INFO[0m - Task exited with return code 0[0m
[2020-07-30 18:50:46,428] {{taskinstance.py:616}} INFO - Dependencies all met for <TaskInstance: S3_dag_test.data_collection 2020-07-27T00:00:00+00:00 [queued]>
[2020-07-30 18:50:46,440] {{taskinstance.py:616}} INFO - Dependencies all met for <TaskInstance: S3_dag_test.data_collection 2020-07-27T00:00:00+00:00 [queued]>
[2020-07-30 18:50:46,441] {{taskinstance.py:834}} INFO - 
--------------------------------------------------------------------------------
[2020-07-30 18:50:46,441] {{taskinstance.py:835}} INFO - Starting attempt 1 of 1
[2020-07-30 18:50:46,442] {{taskinstance.py:836}} INFO - 
--------------------------------------------------------------------------------
[2020-07-30 18:50:46,456] {{taskinstance.py:855}} INFO - Executing <Task(PythonOperator): data_collection> on 2020-07-27T00:00:00+00:00
[2020-07-30 18:50:46,457] {{base_task_runner.py:133}} INFO - Running: ['airflow', 'run', 'S3_dag_test', 'data_collection', '2020-07-27T00:00:00+00:00', '--job_id', '4', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/test_s3.py', '--cfg_path', '/tmp/tmpsnmz4fqx']
[2020-07-30 18:50:47,761] {{base_task_runner.py:115}} INFO - Job 4: Subtask data_collection [2020-07-30 18:50:47,760] {{settings.py:213}} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5519
[2020-07-30 18:50:47,789] {{base_task_runner.py:115}} INFO - Job 4: Subtask data_collection /usr/local/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
[2020-07-30 18:50:47,790] {{base_task_runner.py:115}} INFO - Job 4: Subtask data_collection   """)
[2020-07-30 18:50:48,148] {{base_task_runner.py:115}} INFO - Job 4: Subtask data_collection [2020-07-30 18:50:48,147] {{__init__.py:51}} INFO - Using executor LocalExecutor
[2020-07-30 18:50:48,817] {{base_task_runner.py:115}} INFO - Job 4: Subtask data_collection [2020-07-30 18:50:48,816] {{dagbag.py:90}} INFO - Filling up the DagBag from /usr/local/airflow/dags/test_s3.py
[2020-07-30 18:50:48,848] {{base_task_runner.py:115}} INFO - Job 4: Subtask data_collection /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2020-07-30 18:50:48,848] {{base_task_runner.py:115}} INFO - Job 4: Subtask data_collection   DeprecationWarning)
[2020-07-30 18:50:48,857] {{base_task_runner.py:115}} INFO - Job 4: Subtask data_collection /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2020-07-30 18:50:48,858] {{base_task_runner.py:115}} INFO - Job 4: Subtask data_collection   DeprecationWarning)
[2020-07-30 18:50:49,686] {{base_task_runner.py:115}} INFO - Job 4: Subtask data_collection [2020-07-30 18:50:49,685] {{cli.py:516}} INFO - Running <TaskInstance: S3_dag_test.data_collection 2020-07-27T00:00:00+00:00 [running]> on host 6097e8989e8b
[2020-07-30 18:50:49,721] {{python_operator.py:105}} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=S3_dag_test
AIRFLOW_CTX_TASK_ID=data_collection
AIRFLOW_CTX_EXECUTION_DATE=2020-07-27T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-07-27T00:00:00+00:00
[2020-07-30 18:50:49,936] {{python_operator.py:114}} INFO - Done. Returned value was: None
[2020-07-30 18:50:51,378] {{logging_mixin.py:95}} INFO - [[34m2020-07-30 18:50:51,377[0m] {{[34mlocal_task_job.py:[0m105}} INFO[0m - Task exited with return code 0[0m
