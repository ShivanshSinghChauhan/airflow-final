[2020-08-04 20:39:00,502] {{taskinstance.py:616}} - Dependencies all met for <TaskInstance: S3_dag_test.upload_to_salesforce1 2020-08-04T00:00:00+00:00 [queued]>
[2020-08-04 20:39:00,558] {{taskinstance.py:616}} - Dependencies all met for <TaskInstance: S3_dag_test.upload_to_salesforce1 2020-08-04T00:00:00+00:00 [queued]>
[2020-08-04 20:39:00,560] {{taskinstance.py:834}} - 
--------------------------------------------------------------------------------
[2020-08-04 20:39:00,560] {{taskinstance.py:835}} - Starting attempt 1 of 1
[2020-08-04 20:39:00,560] {{taskinstance.py:836}} - 
--------------------------------------------------------------------------------
[2020-08-04 20:39:00,578] {{taskinstance.py:855}} - Executing <Task(PythonOperator): upload_to_salesforce1> on 2020-08-04T00:00:00+00:00
[2020-08-04 20:39:00,579] {{base_task_runner.py:133}} - Running: ['airflow', 'run', 'S3_dag_test', 'upload_to_salesforce1', '2020-08-04T00:00:00+00:00', '--job_id', '8', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/test_s3.py', '--cfg_path', '/tmp/tmpu9oknyvb']
[2020-08-04 20:39:01,912] {{base_task_runner.py:115}} - Job 8: Subtask upload_to_salesforce1 [2020-08-04 20:39:01,911] {{settings.py:213}} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=993
[2020-08-04 20:39:01,961] {{base_task_runner.py:115}} - Job 8: Subtask upload_to_salesforce1 /usr/local/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
[2020-08-04 20:39:01,961] {{base_task_runner.py:115}} - Job 8: Subtask upload_to_salesforce1   """)
[2020-08-04 20:39:02,257] {{base_task_runner.py:115}} - Job 8: Subtask upload_to_salesforce1 [2020-08-04 20:39:02,254] {{__init__.py:51}} INFO - Using executor LocalExecutor
[2020-08-04 20:39:03,216] {{base_task_runner.py:115}} - Job 8: Subtask upload_to_salesforce1 [2020-08-04 20:39:03,215] {{dagbag.py:90}} INFO - Filling up the DagBag from /usr/local/airflow/dags/test_s3.py
[2020-08-04 20:39:03,234] {{base_task_runner.py:115}} - Job 8: Subtask upload_to_salesforce1 /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2020-08-04 20:39:03,235] {{base_task_runner.py:115}} - Job 8: Subtask upload_to_salesforce1   DeprecationWarning)
[2020-08-04 20:39:03,237] {{base_task_runner.py:115}} - Job 8: Subtask upload_to_salesforce1 /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2020-08-04 20:39:03,238] {{base_task_runner.py:115}} - Job 8: Subtask upload_to_salesforce1   DeprecationWarning)
[2020-08-04 20:39:03,995] {{base_task_runner.py:115}} - Job 8: Subtask upload_to_salesforce1 [2020-08-04 20:39:03,995] {{cli.py:516}} INFO - Running <TaskInstance: S3_dag_test.upload_to_salesforce1 2020-08-04T00:00:00+00:00 [running]> on host b0d2f8e450cd
[2020-08-04 20:39:04,027] {{python_operator.py:105}} - Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=S3_dag_test
AIRFLOW_CTX_TASK_ID=upload_to_salesforce1
AIRFLOW_CTX_EXECUTION_DATE=2020-08-04T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-08-04T00:00:00+00:00
[2020-08-04 20:39:05,664] {{python_operator.py:114}} - Done. Returned value was: None
[2020-08-04 20:39:10,441] {{logging_mixin.py:95}} - [[34m2020-08-04 20:39:10,441[0m] {{[34mlocal_task_job.py:[0m105}} INFO[0m - Task exited with return code 0[0m
time ---> [2020-08-04 23:07:58,034]|filename and line ---> {{taskinstance.py:616}}|level ---> INFO message ---> Dependencies all met for <TaskInstance: S3_dag_test.upload_to_salesforce1 2020-08-04T00:00:00+00:00 [queued]>
time ---> [2020-08-04 23:07:58,067]|filename and line ---> {{taskinstance.py:616}}|level ---> INFO message ---> Dependencies all met for <TaskInstance: S3_dag_test.upload_to_salesforce1 2020-08-04T00:00:00+00:00 [queued]>
time ---> [2020-08-04 23:07:58,069]|filename and line ---> {{taskinstance.py:834}}|level ---> INFO message ---> 
--------------------------------------------------------------------------------
time ---> [2020-08-04 23:07:58,070]|filename and line ---> {{taskinstance.py:835}}|level ---> INFO message ---> Starting attempt 1 of 1
time ---> [2020-08-04 23:07:58,070]|filename and line ---> {{taskinstance.py:836}}|level ---> INFO message ---> 
--------------------------------------------------------------------------------
time ---> [2020-08-04 23:07:58,118]|filename and line ---> {{taskinstance.py:855}}|level ---> INFO message ---> Executing <Task(PythonOperator): upload_to_salesforce1> on 2020-08-04T00:00:00+00:00
time ---> [2020-08-04 23:07:58,118]|filename and line ---> {{base_task_runner.py:133}}|level ---> INFO message ---> Running: ['airflow', 'run', 'S3_dag_test', 'upload_to_salesforce1', '2020-08-04T00:00:00+00:00', '--job_id', '8', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/test_s3.py', '--cfg_path', '/tmp/tmp0cmkz7n7']
time ---> [2020-08-04 23:07:59,244]|filename and line ---> {{base_task_runner.py:115}}|level ---> INFO message ---> Job 8: Subtask upload_to_salesforce1 [2020-08-04 23:07:59,243] {{settings.py:213}} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=1039
time ---> [2020-08-04 23:07:59,264]|filename and line ---> {{base_task_runner.py:115}}|level ---> INFO message ---> Job 8: Subtask upload_to_salesforce1 /usr/local/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
time ---> [2020-08-04 23:07:59,265]|filename and line ---> {{base_task_runner.py:115}}|level ---> INFO message ---> Job 8: Subtask upload_to_salesforce1   """)
time ---> [2020-08-04 23:07:59,512]|filename and line ---> {{base_task_runner.py:115}}|level ---> INFO message ---> Job 8: Subtask upload_to_salesforce1 [2020-08-04 23:07:59,512] {{__init__.py:51}} INFO - Using executor LocalExecutor
time ---> [2020-08-04 23:07:59,943]|filename and line ---> {{base_task_runner.py:115}}|level ---> INFO message ---> Job 8: Subtask upload_to_salesforce1 [2020-08-04 23:07:59,943] {{dagbag.py:90}} INFO - Filling up the DagBag from /usr/local/airflow/dags/test_s3.py
time ---> [2020-08-04 23:07:59,959]|filename and line ---> {{base_task_runner.py:115}}|level ---> INFO message ---> Job 8: Subtask upload_to_salesforce1 /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
time ---> [2020-08-04 23:07:59,960]|filename and line ---> {{base_task_runner.py:115}}|level ---> INFO message ---> Job 8: Subtask upload_to_salesforce1   DeprecationWarning)
time ---> [2020-08-04 23:07:59,961]|filename and line ---> {{base_task_runner.py:115}}|level ---> INFO message ---> Job 8: Subtask upload_to_salesforce1 /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
time ---> [2020-08-04 23:07:59,962]|filename and line ---> {{base_task_runner.py:115}}|level ---> INFO message ---> Job 8: Subtask upload_to_salesforce1   DeprecationWarning)
time ---> [2020-08-04 23:08:00,668]|filename and line ---> {{base_task_runner.py:115}}|level ---> INFO message ---> Job 8: Subtask upload_to_salesforce1 [2020-08-04 23:08:00,667] {{cli.py:516}} INFO - Running <TaskInstance: S3_dag_test.upload_to_salesforce1 2020-08-04T00:00:00+00:00 [running]> on host a4191b27d80a
time ---> [2020-08-04 23:08:00,733]|filename and line ---> {{python_operator.py:105}}|level ---> INFO message ---> Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=S3_dag_test
AIRFLOW_CTX_TASK_ID=upload_to_salesforce1
AIRFLOW_CTX_EXECUTION_DATE=2020-08-04T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-08-04T00:00:00+00:00
time ---> [2020-08-04 23:08:12,865]|filename and line ---> {{python_operator.py:114}}|level ---> INFO message ---> Done. Returned value was: None
time ---> [2020-08-04 23:08:13,014]|filename and line ---> {{logging_mixin.py:95}}|level ---> INFO message ---> [[34m2020-08-04 23:08:13,014[0m] {{[34mlocal_task_job.py:[0m172}} WARNING[0m - State of this instance has been externally set to [1msuccess[0m. Taking the poison pill.[0m
time ---> [2020-08-04 23:08:13,017]|filename and line ---> {{helpers.py:319}}|level ---> INFO message ---> Sending Signals.SIGTERM to GPID 1039
time ---> [2020-08-04 23:08:13,035]|filename and line ---> {{helpers.py:297}}|level ---> INFO message ---> Process psutil.Process(pid=1039, status='terminated') (1039) terminated with exit code -15
time ---> [2020-08-04 23:08:13,036]|filename and line ---> {{logging_mixin.py:95}}|level ---> INFO message ---> [[34m2020-08-04 23:08:13,036[0m] {{[34mlocal_task_job.py:[0m105}} INFO[0m - Task exited with return code 0[0m
time ---> [2020-08-04 23:16:16,035] | filename and line ---> {{taskinstance.py:616}} | level ---> INFO message ---> Dependencies all met for <TaskInstance: S3_dag_test.upload_to_salesforce1 2020-08-04T00:00:00+00:00 [queued]>
time ---> [2020-08-04 23:16:16,122] | filename and line ---> {{taskinstance.py:616}} | level ---> INFO message ---> Dependencies all met for <TaskInstance: S3_dag_test.upload_to_salesforce1 2020-08-04T00:00:00+00:00 [queued]>
time ---> [2020-08-04 23:16:16,123] | filename and line ---> {{taskinstance.py:834}} | level ---> INFO message ---> 
--------------------------------------------------------------------------------
time ---> [2020-08-04 23:16:16,124] | filename and line ---> {{taskinstance.py:835}} | level ---> INFO message ---> Starting attempt 1 of 1
time ---> [2020-08-04 23:16:16,124] | filename and line ---> {{taskinstance.py:836}} | level ---> INFO message ---> 
--------------------------------------------------------------------------------
time ---> [2020-08-04 23:16:16,167] | filename and line ---> {{taskinstance.py:855}} | level ---> INFO message ---> Executing <Task(PythonOperator): upload_to_salesforce1> on 2020-08-04T00:00:00+00:00
time ---> [2020-08-04 23:16:16,168] | filename and line ---> {{base_task_runner.py:133}} | level ---> INFO message ---> Running: ['airflow', 'run', 'S3_dag_test', 'upload_to_salesforce1', '2020-08-04T00:00:00+00:00', '--job_id', '9', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/test_s3.py', '--cfg_path', '/tmp/tmp16zx48s6']
time ---> [2020-08-04 23:16:17,528] | filename and line ---> {{base_task_runner.py:115}} | level ---> INFO message ---> Job 9: Subtask upload_to_salesforce1 [2020-08-04 23:16:17,528] {{settings.py:213}} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=1394
time ---> [2020-08-04 23:16:17,548] | filename and line ---> {{base_task_runner.py:115}} | level ---> INFO message ---> Job 9: Subtask upload_to_salesforce1 /usr/local/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
time ---> [2020-08-04 23:16:17,548] | filename and line ---> {{base_task_runner.py:115}} | level ---> INFO message ---> Job 9: Subtask upload_to_salesforce1   """)
time ---> [2020-08-04 23:16:17,700] | filename and line ---> {{base_task_runner.py:115}} | level ---> INFO message ---> Job 9: Subtask upload_to_salesforce1 [2020-08-04 23:16:17,699] {{__init__.py:51}} INFO - Using executor LocalExecutor
time ---> [2020-08-04 23:16:18,767] | filename and line ---> {{base_task_runner.py:115}} | level ---> INFO message ---> Job 9: Subtask upload_to_salesforce1 [2020-08-04 23:16:18,767] {{dagbag.py:90}} INFO - Filling up the DagBag from /usr/local/airflow/dags/test_s3.py
time ---> [2020-08-04 23:16:18,792] | filename and line ---> {{base_task_runner.py:115}} | level ---> INFO message ---> Job 9: Subtask upload_to_salesforce1 /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
time ---> [2020-08-04 23:16:18,793] | filename and line ---> {{base_task_runner.py:115}} | level ---> INFO message ---> Job 9: Subtask upload_to_salesforce1   DeprecationWarning)
time ---> [2020-08-04 23:16:18,794] | filename and line ---> {{base_task_runner.py:115}} | level ---> INFO message ---> Job 9: Subtask upload_to_salesforce1 /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
time ---> [2020-08-04 23:16:18,794] | filename and line ---> {{base_task_runner.py:115}} | level ---> INFO message ---> Job 9: Subtask upload_to_salesforce1   DeprecationWarning)
time ---> [2020-08-04 23:16:19,285] | filename and line ---> {{base_task_runner.py:115}} | level ---> INFO message ---> Job 9: Subtask upload_to_salesforce1 [2020-08-04 23:16:19,285] {{cli.py:516}} INFO - Running <TaskInstance: S3_dag_test.upload_to_salesforce1 2020-08-04T00:00:00+00:00 [running]> on host 9bf7b91ed690
time ---> [2020-08-04 23:16:19,314] | filename and line ---> {{python_operator.py:105}} | level ---> INFO message ---> Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=S3_dag_test
AIRFLOW_CTX_TASK_ID=upload_to_salesforce1
AIRFLOW_CTX_EXECUTION_DATE=2020-08-04T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-08-04T00:00:00+00:00
time ---> [2020-08-04 23:16:20,679] | filename and line ---> {{python_operator.py:114}} | level ---> INFO message ---> Done. Returned value was: None
time ---> [2020-08-04 23:16:20,981] | filename and line ---> {{logging_mixin.py:95}} | level ---> INFO message ---> [[34m2020-08-04 23:16:20,981[0m] {{[34mlocal_task_job.py:[0m105}} INFO[0m - Task exited with return code 0[0m
[2020-08-07 22:40:17,240] | {{taskinstance.py:616}} | INFO | Dependencies all met for <TaskInstance: S3_dag_test.upload_to_salesforce1 2020-08-04T00:00:00+00:00 [queued]>
[2020-08-07 22:40:17,447] | {{taskinstance.py:616}} | INFO | Dependencies all met for <TaskInstance: S3_dag_test.upload_to_salesforce1 2020-08-04T00:00:00+00:00 [queued]>
[2020-08-07 22:40:17,448] | {{taskinstance.py:834}} | INFO | 
--------------------------------------------------------------------------------
[2020-08-07 22:40:17,450] | {{taskinstance.py:835}} | INFO | Starting attempt 1 of 1
[2020-08-07 22:40:17,451] | {{taskinstance.py:836}} | INFO | 
--------------------------------------------------------------------------------
[2020-08-07 22:40:17,493] | {{taskinstance.py:855}} | INFO | Executing <Task(PythonOperator): upload_to_salesforce1> on 2020-08-04T00:00:00+00:00
[2020-08-07 22:40:17,493] | {{base_task_runner.py:133}} | INFO | Running: ['airflow', 'run', 'S3_dag_test', 'upload_to_salesforce1', '2020-08-04T00:00:00+00:00', '--job_id', '10', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/test_s3.py', '--cfg_path', '/tmp/tmp7w_5r46e']
[2020-08-07 22:40:19,048] | {{base_task_runner.py:115}} | INFO | Job 10: Subtask upload_to_salesforce1 [2020-08-07 22:40:19,047] {{settings.py:213}} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=3256
[2020-08-07 22:40:19,132] | {{base_task_runner.py:115}} | INFO | Job 10: Subtask upload_to_salesforce1 /usr/local/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
[2020-08-07 22:40:19,133] | {{base_task_runner.py:115}} | INFO | Job 10: Subtask upload_to_salesforce1   """)
[2020-08-07 22:40:19,438] | {{base_task_runner.py:115}} | INFO | Job 10: Subtask upload_to_salesforce1 [2020-08-07 22:40:19,438] {{__init__.py:51}} INFO - Using executor LocalExecutor
[2020-08-07 22:40:20,419] | {{base_task_runner.py:115}} | INFO | Job 10: Subtask upload_to_salesforce1 [2020-08-07 22:40:20,417] {{dagbag.py:90}} INFO - Filling up the DagBag from /usr/local/airflow/dags/test_s3.py
[2020-08-07 22:40:20,451] | {{base_task_runner.py:115}} | INFO | Job 10: Subtask upload_to_salesforce1 /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2020-08-07 22:40:20,452] | {{base_task_runner.py:115}} | INFO | Job 10: Subtask upload_to_salesforce1   DeprecationWarning)
[2020-08-07 22:40:20,459] | {{base_task_runner.py:115}} | INFO | Job 10: Subtask upload_to_salesforce1 /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2020-08-07 22:40:20,459] | {{base_task_runner.py:115}} | INFO | Job 10: Subtask upload_to_salesforce1   DeprecationWarning)
[2020-08-07 22:40:21,147] | {{base_task_runner.py:115}} | INFO | Job 10: Subtask upload_to_salesforce1 [2020-08-07 22:40:21,142] {{cli.py:516}} INFO - Running <TaskInstance: S3_dag_test.upload_to_salesforce1 2020-08-04T00:00:00+00:00 [running]> on host 5f4c3a456296
[2020-08-07 22:40:21,267] | {{python_operator.py:105}} | INFO | Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=S3_dag_test
AIRFLOW_CTX_TASK_ID=upload_to_salesforce1
AIRFLOW_CTX_EXECUTION_DATE=2020-08-04T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-08-04T00:00:00+00:00
[2020-08-07 22:40:23,544] | {{python_operator.py:114}} | INFO | Done. Returned value was: None
[2020-08-07 22:40:27,060] | {{logging_mixin.py:95}} | INFO | [[34m2020-08-07 22:40:27,054[0m] {{[34mlocal_task_job.py:[0m105}} INFO[0m - Task exited with return code 0[0m
