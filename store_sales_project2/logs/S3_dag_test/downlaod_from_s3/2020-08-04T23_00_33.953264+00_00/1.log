time ---> [2020-08-04 23:00:51,254] filename and line ---> {{taskinstance.py:616}} level ---> INFO message ---> Dependencies all met for <TaskInstance: S3_dag_test.downlaod_from_s3 2020-08-04T23:00:33.953264+00:00 [queued]>
time ---> [2020-08-04 23:00:51,341] filename and line ---> {{taskinstance.py:616}} level ---> INFO message ---> Dependencies all met for <TaskInstance: S3_dag_test.downlaod_from_s3 2020-08-04T23:00:33.953264+00:00 [queued]>
time ---> [2020-08-04 23:00:51,341] filename and line ---> {{taskinstance.py:834}} level ---> INFO message ---> 
--------------------------------------------------------------------------------
time ---> [2020-08-04 23:00:51,342] filename and line ---> {{taskinstance.py:835}} level ---> INFO message ---> Starting attempt 1 of 1
time ---> [2020-08-04 23:00:51,343] filename and line ---> {{taskinstance.py:836}} level ---> INFO message ---> 
--------------------------------------------------------------------------------
time ---> [2020-08-04 23:00:51,395] filename and line ---> {{taskinstance.py:855}} level ---> INFO message ---> Executing <Task(PythonOperator): downlaod_from_s3> on 2020-08-04T23:00:33.953264+00:00
time ---> [2020-08-04 23:00:51,397] filename and line ---> {{base_task_runner.py:133}} level ---> INFO message ---> Running: ['airflow', 'run', 'S3_dag_test', 'downlaod_from_s3', '2020-08-04T23:00:33.953264+00:00', '--job_id', '5', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/test_s3.py', '--cfg_path', '/tmp/tmpd5lvuv_a']
time ---> [2020-08-04 23:00:53,097] filename and line ---> {{base_task_runner.py:115}} level ---> INFO message ---> Job 5: Subtask downlaod_from_s3 [2020-08-04 23:00:53,096] {{settings.py:213}} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=603
time ---> [2020-08-04 23:00:53,156] filename and line ---> {{base_task_runner.py:115}} level ---> INFO message ---> Job 5: Subtask downlaod_from_s3 /usr/local/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
time ---> [2020-08-04 23:00:53,157] filename and line ---> {{base_task_runner.py:115}} level ---> INFO message ---> Job 5: Subtask downlaod_from_s3   """)
time ---> [2020-08-04 23:00:53,395] filename and line ---> {{base_task_runner.py:115}} level ---> INFO message ---> Job 5: Subtask downlaod_from_s3 [2020-08-04 23:00:53,394] {{__init__.py:51}} INFO - Using executor LocalExecutor
time ---> [2020-08-04 23:00:53,772] filename and line ---> {{base_task_runner.py:115}} level ---> INFO message ---> Job 5: Subtask downlaod_from_s3 [2020-08-04 23:00:53,771] {{dagbag.py:90}} INFO - Filling up the DagBag from /usr/local/airflow/dags/test_s3.py
time ---> [2020-08-04 23:00:53,788] filename and line ---> {{base_task_runner.py:115}} level ---> INFO message ---> Job 5: Subtask downlaod_from_s3 /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
time ---> [2020-08-04 23:00:53,789] filename and line ---> {{base_task_runner.py:115}} level ---> INFO message ---> Job 5: Subtask downlaod_from_s3   DeprecationWarning)
time ---> [2020-08-04 23:00:53,790] filename and line ---> {{base_task_runner.py:115}} level ---> INFO message ---> Job 5: Subtask downlaod_from_s3 /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
time ---> [2020-08-04 23:00:53,791] filename and line ---> {{base_task_runner.py:115}} level ---> INFO message ---> Job 5: Subtask downlaod_from_s3   DeprecationWarning)
time ---> [2020-08-04 23:00:54,642] filename and line ---> {{base_task_runner.py:115}} level ---> INFO message ---> Job 5: Subtask downlaod_from_s3 [2020-08-04 23:00:54,641] {{cli.py:516}} INFO - Running <TaskInstance: S3_dag_test.downlaod_from_s3 2020-08-04T23:00:33.953264+00:00 [running]> on host 140604d641fe
time ---> [2020-08-04 23:00:54,695] filename and line ---> {{python_operator.py:105}} level ---> INFO message ---> Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=S3_dag_test
AIRFLOW_CTX_TASK_ID=downlaod_from_s3
AIRFLOW_CTX_EXECUTION_DATE=2020-08-04T23:00:33.953264+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2020-08-04T23:00:33.953264+00:00
time ---> [2020-08-04 23:00:56,010] filename and line ---> {{python_operator.py:114}} level ---> INFO message ---> Done. Returned value was: None
time ---> [2020-08-04 23:00:56,173] filename and line ---> {{logging_mixin.py:95}} level ---> INFO message ---> [[34m2020-08-04 23:00:56,172[0m] {{[34mlocal_task_job.py:[0m172}} WARNING[0m - State of this instance has been externally set to [1msuccess[0m. Taking the poison pill.[0m
time ---> [2020-08-04 23:00:56,176] filename and line ---> {{helpers.py:319}} level ---> INFO message ---> Sending Signals.SIGTERM to GPID 603
time ---> [2020-08-04 23:00:56,207] filename and line ---> {{helpers.py:297}} level ---> INFO message ---> Process psutil.Process(pid=603, status='terminated') (603) terminated with exit code -15
time ---> [2020-08-04 23:00:56,208] filename and line ---> {{logging_mixin.py:95}} level ---> INFO message ---> [[34m2020-08-04 23:00:56,208[0m] {{[34mlocal_task_job.py:[0m105}} INFO[0m - Task exited with return code 0[0m
