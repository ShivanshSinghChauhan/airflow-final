[2020-07-29 19:17:50,837] {{taskinstance.py:616}} INFO - Dependencies all met for <TaskInstance: S3_dag_test.downlaod_from_s3 2020-07-27T00:00:00+00:00 [queued]>
[2020-07-29 19:17:50,862] {{taskinstance.py:616}} INFO - Dependencies all met for <TaskInstance: S3_dag_test.downlaod_from_s3 2020-07-27T00:00:00+00:00 [queued]>
[2020-07-29 19:17:50,863] {{taskinstance.py:834}} INFO - 
--------------------------------------------------------------------------------
[2020-07-29 19:17:50,864] {{taskinstance.py:835}} INFO - Starting attempt 1 of 1
[2020-07-29 19:17:50,864] {{taskinstance.py:836}} INFO - 
--------------------------------------------------------------------------------
[2020-07-29 19:17:50,892] {{taskinstance.py:855}} INFO - Executing <Task(PythonOperator): downlaod_from_s3> on 2020-07-27T00:00:00+00:00
[2020-07-29 19:17:50,893] {{base_task_runner.py:133}} INFO - Running: ['airflow', 'run', 'S3_dag_test', 'downlaod_from_s3', '2020-07-27T00:00:00+00:00', '--job_id', '4', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/test_s3.py', '--cfg_path', '/tmp/tmpceixy9j6']
[2020-07-29 19:17:52,328] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3 [2020-07-29 19:17:52,328] {{settings.py:213}} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=1765
[2020-07-29 19:17:52,348] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3 /usr/local/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
[2020-07-29 19:17:52,348] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3   """)
[2020-07-29 19:17:52,491] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3 [2020-07-29 19:17:52,490] {{__init__.py:51}} INFO - Using executor LocalExecutor
[2020-07-29 19:17:53,031] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3 [2020-07-29 19:17:53,030] {{dagbag.py:90}} INFO - Filling up the DagBag from /usr/local/airflow/dags/test_s3.py
[2020-07-29 19:17:53,045] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3 /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2020-07-29 19:17:53,046] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3   DeprecationWarning)
[2020-07-29 19:17:53,051] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3 /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2020-07-29 19:17:53,051] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3   DeprecationWarning)
[2020-07-29 19:17:53,617] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3 [2020-07-29 19:17:53,617] {{cli.py:516}} INFO - Running <TaskInstance: S3_dag_test.downlaod_from_s3 2020-07-27T00:00:00+00:00 [running]> on host 498b75d7734d
[2020-07-29 19:17:53,650] {{python_operator.py:105}} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=S3_dag_test
AIRFLOW_CTX_TASK_ID=downlaod_from_s3
AIRFLOW_CTX_EXECUTION_DATE=2020-07-27T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-07-27T00:00:00+00:00
[2020-07-29 19:17:54,872] {{python_operator.py:114}} INFO - Done. Returned value was: None
[2020-07-29 19:17:55,809] {{logging_mixin.py:95}} INFO - [[34m2020-07-29 19:17:55,808[0m] {{[34mlocal_task_job.py:[0m105}} INFO[0m - Task exited with return code 0[0m
[2020-07-29 19:33:22,827] {{taskinstance.py:616}} INFO - Dependencies all met for <TaskInstance: S3_dag_test.downlaod_from_s3 2020-07-27T00:00:00+00:00 [queued]>
[2020-07-29 19:33:22,848] {{taskinstance.py:616}} INFO - Dependencies all met for <TaskInstance: S3_dag_test.downlaod_from_s3 2020-07-27T00:00:00+00:00 [queued]>
[2020-07-29 19:33:22,849] {{taskinstance.py:834}} INFO - 
--------------------------------------------------------------------------------
[2020-07-29 19:33:22,849] {{taskinstance.py:835}} INFO - Starting attempt 1 of 1
[2020-07-29 19:33:22,850] {{taskinstance.py:836}} INFO - 
--------------------------------------------------------------------------------
[2020-07-29 19:33:22,871] {{taskinstance.py:855}} INFO - Executing <Task(PythonOperator): downlaod_from_s3> on 2020-07-27T00:00:00+00:00
[2020-07-29 19:33:22,872] {{base_task_runner.py:133}} INFO - Running: ['airflow', 'run', 'S3_dag_test', 'downlaod_from_s3', '2020-07-27T00:00:00+00:00', '--job_id', '4', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/test_s3.py', '--cfg_path', '/tmp/tmprk74exjh']
[2020-07-29 19:33:24,049] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3 [2020-07-29 19:33:24,048] {{settings.py:213}} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=603
[2020-07-29 19:33:24,072] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3 /usr/local/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
[2020-07-29 19:33:24,073] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3   """)
[2020-07-29 19:33:24,824] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3 [2020-07-29 19:33:24,820] {{__init__.py:51}} INFO - Using executor LocalExecutor
[2020-07-29 19:33:25,486] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3 [2020-07-29 19:33:25,486] {{dagbag.py:90}} INFO - Filling up the DagBag from /usr/local/airflow/dags/test_s3.py
[2020-07-29 19:33:25,500] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3 /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2020-07-29 19:33:25,501] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3   DeprecationWarning)
[2020-07-29 19:33:25,502] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3 /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2020-07-29 19:33:25,503] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3   DeprecationWarning)
[2020-07-29 19:33:26,172] {{base_task_runner.py:115}} INFO - Job 4: Subtask downlaod_from_s3 [2020-07-29 19:33:26,172] {{cli.py:516}} INFO - Running <TaskInstance: S3_dag_test.downlaod_from_s3 2020-07-27T00:00:00+00:00 [running]> on host 1fdeb61556ef
[2020-07-29 19:33:26,267] {{python_operator.py:105}} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=S3_dag_test
AIRFLOW_CTX_TASK_ID=downlaod_from_s3
AIRFLOW_CTX_EXECUTION_DATE=2020-07-27T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-07-27T00:00:00+00:00
[2020-07-29 19:33:27,298] {{python_operator.py:114}} INFO - Done. Returned value was: None
[2020-07-29 19:33:27,811] {{logging_mixin.py:95}} INFO - [[34m2020-07-29 19:33:27,810[0m] {{[34mlocal_task_job.py:[0m172}} WARNING[0m - State of this instance has been externally set to [1msuccess[0m. Taking the poison pill.[0m
[2020-07-29 19:33:27,813] {{helpers.py:319}} INFO - Sending Signals.SIGTERM to GPID 603
[2020-07-29 19:33:27,835] {{helpers.py:297}} INFO - Process psutil.Process(pid=603, status='terminated') (603) terminated with exit code -15
[2020-07-29 19:33:27,837] {{logging_mixin.py:95}} INFO - [[34m2020-07-29 19:33:27,836[0m] {{[34mlocal_task_job.py:[0m105}} INFO[0m - Task exited with return code 0[0m
[2020-07-30 18:50:58,401] {{taskinstance.py:616}} INFO - Dependencies all met for <TaskInstance: S3_dag_test.downlaod_from_s3 2020-07-27T00:00:00+00:00 [queued]>
[2020-07-30 18:50:58,478] {{taskinstance.py:616}} INFO - Dependencies all met for <TaskInstance: S3_dag_test.downlaod_from_s3 2020-07-27T00:00:00+00:00 [queued]>
[2020-07-30 18:50:58,480] {{taskinstance.py:834}} INFO - 
--------------------------------------------------------------------------------
[2020-07-30 18:50:58,480] {{taskinstance.py:835}} INFO - Starting attempt 1 of 1
[2020-07-30 18:50:58,481] {{taskinstance.py:836}} INFO - 
--------------------------------------------------------------------------------
[2020-07-30 18:50:58,517] {{taskinstance.py:855}} INFO - Executing <Task(PythonOperator): downlaod_from_s3> on 2020-07-27T00:00:00+00:00
[2020-07-30 18:50:58,519] {{base_task_runner.py:133}} INFO - Running: ['airflow', 'run', 'S3_dag_test', 'downlaod_from_s3', '2020-07-27T00:00:00+00:00', '--job_id', '6', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/test_s3.py', '--cfg_path', '/tmp/tmpecrhh0l7']
[2020-07-30 18:51:02,607] {{base_task_runner.py:115}} INFO - Job 6: Subtask downlaod_from_s3 [2020-07-30 18:51:02,606] {{settings.py:213}} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5650
[2020-07-30 18:51:02,682] {{base_task_runner.py:115}} INFO - Job 6: Subtask downlaod_from_s3 /usr/local/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
[2020-07-30 18:51:02,682] {{base_task_runner.py:115}} INFO - Job 6: Subtask downlaod_from_s3   """)
[2020-07-30 18:51:03,628] {{base_task_runner.py:115}} INFO - Job 6: Subtask downlaod_from_s3 [2020-07-30 18:51:03,626] {{__init__.py:51}} INFO - Using executor LocalExecutor
[2020-07-30 18:51:05,639] {{base_task_runner.py:115}} INFO - Job 6: Subtask downlaod_from_s3 [2020-07-30 18:51:05,637] {{dagbag.py:90}} INFO - Filling up the DagBag from /usr/local/airflow/dags/test_s3.py
[2020-07-30 18:51:05,660] {{base_task_runner.py:115}} INFO - Job 6: Subtask downlaod_from_s3 /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2020-07-30 18:51:05,660] {{base_task_runner.py:115}} INFO - Job 6: Subtask downlaod_from_s3   DeprecationWarning)
[2020-07-30 18:51:05,665] {{base_task_runner.py:115}} INFO - Job 6: Subtask downlaod_from_s3 /usr/local/lib/python3.7/site-packages/airflow/utils/helpers.py:425: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2020-07-30 18:51:05,665] {{base_task_runner.py:115}} INFO - Job 6: Subtask downlaod_from_s3   DeprecationWarning)
[2020-07-30 18:51:06,662] {{base_task_runner.py:115}} INFO - Job 6: Subtask downlaod_from_s3 [2020-07-30 18:51:06,659] {{cli.py:516}} INFO - Running <TaskInstance: S3_dag_test.downlaod_from_s3 2020-07-27T00:00:00+00:00 [running]> on host 6097e8989e8b
[2020-07-30 18:51:06,710] {{python_operator.py:105}} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=S3_dag_test
AIRFLOW_CTX_TASK_ID=downlaod_from_s3
AIRFLOW_CTX_EXECUTION_DATE=2020-07-27T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-07-27T00:00:00+00:00
[2020-07-30 18:51:08,849] {{python_operator.py:114}} INFO - Done. Returned value was: None
[2020-07-30 18:51:13,401] {{logging_mixin.py:95}} INFO - [[34m2020-07-30 18:51:13,401[0m] {{[34mlocal_task_job.py:[0m105}} INFO[0m - Task exited with return code 0[0m
