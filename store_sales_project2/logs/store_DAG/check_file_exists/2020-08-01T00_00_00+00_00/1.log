Dependencies all met for <TaskInstance: store_DAG.check_file_exists 2020-08-01T00:00:00+00:00 [queued]>
Dependencies all met for <TaskInstance: store_DAG.check_file_exists 2020-08-01T00:00:00+00:00 [queued]>

--------------------------------------------------------------------------------
Starting attempt 1 of 3

--------------------------------------------------------------------------------
Executing <Task(BashOperator): check_file_exists> on 2020-08-01T00:00:00+00:00
Running: ['airflow', 'run', 'store_DAG', 'check_file_exists', '2020-08-01T00:00:00+00:00', '--job_id', '30', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/store_DAG.py', '--cfg_path', '/tmp/tmp2anpucj8']
Job 30: Subtask check_file_exists [2020-08-04 20:53:38,418] {{settings.py:213}} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=1730
Job 30: Subtask check_file_exists /usr/local/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
Job 30: Subtask check_file_exists   """)
Job 30: Subtask check_file_exists [2020-08-04 20:53:40,962] {{__init__.py:51}} INFO - Using executor LocalExecutor
Job 30: Subtask check_file_exists [2020-08-04 20:53:49,872] {{dagbag.py:90}} INFO - Filling up the DagBag from /usr/local/airflow/dags/store_DAG.py
Job 30: Subtask check_file_exists [2020-08-04 20:53:50,605] {{cli.py:516}} INFO - Running <TaskInstance: store_DAG.check_file_exists 2020-08-01T00:00:00+00:00 [running]> on host 6a822f9627d0
Tmp dir root location: 
 /tmp
Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=store_DAG
AIRFLOW_CTX_TASK_ID=check_file_exists
AIRFLOW_CTX_EXECUTION_DATE=2020-08-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-08-01T00:00:00+00:00
Temporary script location: /tmp/airflowtmp132z69v4/check_file_existsn_dunfc5
Running command: shasum ~/store_files_airflow/raw_store_transactions.csv
Output:
e9e298e9629d72f3255b4838ba07bd220150a146  /usr/local/airflow/store_files_airflow/raw_store_transactions.csv
Command exited with return code 0
[[34m2020-08-04 20:53:54,823[0m] {{[34mlocal_task_job.py:[0m172}} WARNING[0m - State of this instance has been externally set to [1msuccess[0m. Taking the poison pill.[0m
Sending Signals.SIGTERM to GPID 1730
Process psutil.Process(pid=1730, status='terminated') (1730) terminated with exit code -15
[[34m2020-08-04 20:53:55,570[0m] {{[34mlocal_task_job.py:[0m105}} INFO[0m - Task exited with return code 0[0m
message ----> Dependencies all met for <TaskInstance: store_DAG.check_file_exists 2020-08-01T00:00:00+00:00 [queued]>
message ----> Dependencies all met for <TaskInstance: store_DAG.check_file_exists 2020-08-01T00:00:00+00:00 [queued]>
message ----> 
--------------------------------------------------------------------------------
message ----> Starting attempt 1 of 3
message ----> 
--------------------------------------------------------------------------------
message ----> Executing <Task(BashOperator): check_file_exists> on 2020-08-01T00:00:00+00:00
message ----> Running: ['airflow', 'run', 'store_DAG', 'check_file_exists', '2020-08-01T00:00:00+00:00', '--job_id', '28', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/store_DAG.py', '--cfg_path', '/tmp/tmpev1tggqk']
message ----> Job 28: Subtask check_file_exists [2020-08-04 21:11:21,815] {{settings.py:213}} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=2204
message ----> Job 28: Subtask check_file_exists /usr/local/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
message ----> Job 28: Subtask check_file_exists   """)
message ----> Job 28: Subtask check_file_exists [2020-08-04 21:11:23,274] {{__init__.py:51}} INFO - Using executor LocalExecutor
message ----> Job 28: Subtask check_file_exists [2020-08-04 21:11:25,256] {{dagbag.py:90}} INFO - Filling up the DagBag from /usr/local/airflow/dags/store_DAG.py
message ----> Job 28: Subtask check_file_exists [2020-08-04 21:11:25,497] {{cli.py:516}} INFO - Running <TaskInstance: store_DAG.check_file_exists 2020-08-01T00:00:00+00:00 [running]> on host 0885e5a330eb
message ----> Tmp dir root location: 
 /tmp
message ----> Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=store_DAG
AIRFLOW_CTX_TASK_ID=check_file_exists
AIRFLOW_CTX_EXECUTION_DATE=2020-08-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-08-01T00:00:00+00:00
message ----> Temporary script location: /tmp/airflowtmpm7jduzoq/check_file_existssmnnw8fc
message ----> Running command: shasum ~/store_files_airflow/raw_store_transactions.csv
message ----> Output:
message ----> e9e298e9629d72f3255b4838ba07bd220150a146  /usr/local/airflow/store_files_airflow/raw_store_transactions.csv
message ----> Command exited with return code 0
message ----> [[34m2020-08-04 21:11:28,908[0m] {{[34mlocal_task_job.py:[0m105}} INFO[0m - Task exited with return code 0[0m
