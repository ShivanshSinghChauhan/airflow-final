[2020-07-30 22:01:54,961] {{taskinstance.py:616}} INFO - Dependencies all met for <TaskInstance: store_DAG.check_file_exists 2020-07-29T00:00:00+00:00 [queued]>
[2020-07-30 22:01:55,014] {{taskinstance.py:616}} INFO - Dependencies all met for <TaskInstance: store_DAG.check_file_exists 2020-07-29T00:00:00+00:00 [queued]>
[2020-07-30 22:01:55,021] {{taskinstance.py:834}} INFO - 
--------------------------------------------------------------------------------
[2020-07-30 22:01:55,023] {{taskinstance.py:835}} INFO - Starting attempt 1 of 3
[2020-07-30 22:01:55,025] {{taskinstance.py:836}} INFO - 
--------------------------------------------------------------------------------
[2020-07-30 22:01:55,100] {{taskinstance.py:855}} INFO - Executing <Task(BashOperator): check_file_exists> on 2020-07-29T00:00:00+00:00
[2020-07-30 22:01:55,102] {{base_task_runner.py:133}} INFO - Running: ['airflow', 'run', 'store_DAG', 'check_file_exists', '2020-07-29T00:00:00+00:00', '--job_id', '26', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/store_DAG.py', '--cfg_path', '/tmp/tmpyko34s3n']
[2020-07-30 22:02:01,074] {{base_task_runner.py:115}} INFO - Job 26: Subtask check_file_exists [2020-07-30 22:02:01,069] {{settings.py:213}} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=7701
[2020-07-30 22:02:01,347] {{base_task_runner.py:115}} INFO - Job 26: Subtask check_file_exists /usr/local/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
[2020-07-30 22:02:01,347] {{base_task_runner.py:115}} INFO - Job 26: Subtask check_file_exists   """)
[2020-07-30 22:02:02,154] {{base_task_runner.py:115}} INFO - Job 26: Subtask check_file_exists [2020-07-30 22:02:02,145] {{__init__.py:51}} INFO - Using executor LocalExecutor
[2020-07-30 22:02:04,830] {{base_task_runner.py:115}} INFO - Job 26: Subtask check_file_exists [2020-07-30 22:02:04,824] {{dagbag.py:90}} INFO - Filling up the DagBag from /usr/local/airflow/dags/store_DAG.py
[2020-07-30 22:02:05,269] {{base_task_runner.py:115}} INFO - Job 26: Subtask check_file_exists [2020-07-30 22:02:05,267] {{cli.py:516}} INFO - Running <TaskInstance: store_DAG.check_file_exists 2020-07-29T00:00:00+00:00 [running]> on host 6097e8989e8b
[2020-07-30 22:02:05,448] {{bash_operator.py:81}} INFO - Tmp dir root location: 
 /tmp
[2020-07-30 22:02:05,463] {{bash_operator.py:91}} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=store_DAG
AIRFLOW_CTX_TASK_ID=check_file_exists
AIRFLOW_CTX_EXECUTION_DATE=2020-07-29T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-07-29T00:00:00+00:00
[2020-07-30 22:02:05,465] {{bash_operator.py:105}} INFO - Temporary script location: /tmp/airflowtmp3tmjwrca/check_file_existso2d8eal4
[2020-07-30 22:02:05,469] {{bash_operator.py:115}} INFO - Running command: shasum ~/store_files_airflow/raw_store_transactions.csv
[2020-07-30 22:02:05,535] {{bash_operator.py:124}} INFO - Output:
[2020-07-30 22:02:05,814] {{bash_operator.py:128}} INFO - e9e298e9629d72f3255b4838ba07bd220150a146  /usr/local/airflow/store_files_airflow/raw_store_transactions.csv
[2020-07-30 22:02:05,815] {{bash_operator.py:132}} INFO - Command exited with return code 0
[2020-07-30 22:02:09,915] {{logging_mixin.py:95}} INFO - [[34m2020-07-30 22:02:09,914[0m] {{[34mlocal_task_job.py:[0m105}} INFO[0m - Task exited with return code 0[0m
[2020-08-04 20:46:16,376] {{taskinstance.py:616}} time Dependencies all met for <TaskInstance: store_DAG.check_file_exists 2020-07-29T00:00:00+00:00 [queued]>
[2020-08-04 20:46:16,455] {{taskinstance.py:616}} time Dependencies all met for <TaskInstance: store_DAG.check_file_exists 2020-07-29T00:00:00+00:00 [queued]>
[2020-08-04 20:46:16,458] {{taskinstance.py:834}} time 
--------------------------------------------------------------------------------
[2020-08-04 20:46:16,463] {{taskinstance.py:835}} time Starting attempt 1 of 3
[2020-08-04 20:46:16,467] {{taskinstance.py:836}} time 
--------------------------------------------------------------------------------
[2020-08-04 20:46:16,603] {{taskinstance.py:855}} time Executing <Task(BashOperator): check_file_exists> on 2020-07-29T00:00:00+00:00
[2020-08-04 20:46:16,610] {{base_task_runner.py:133}} time Running: ['airflow', 'run', 'store_DAG', 'check_file_exists', '2020-07-29T00:00:00+00:00', '--job_id', '22', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/store_DAG.py', '--cfg_path', '/tmp/tmpd1uphorg']
[2020-08-04 20:46:31,719] {{base_task_runner.py:115}} time Job 22: Subtask check_file_exists [2020-08-04 20:46:31,713] {{settings.py:213}} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=1634
[2020-08-04 20:46:32,075] {{base_task_runner.py:115}} time Job 22: Subtask check_file_exists /usr/local/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
[2020-08-04 20:46:32,076] {{base_task_runner.py:115}} time Job 22: Subtask check_file_exists   """)
[2020-08-04 20:46:34,160] {{base_task_runner.py:115}} time Job 22: Subtask check_file_exists [2020-08-04 20:46:34,150] {{__init__.py:51}} INFO - Using executor LocalExecutor
[2020-08-04 20:46:38,973] {{base_task_runner.py:115}} time Job 22: Subtask check_file_exists [2020-08-04 20:46:38,969] {{dagbag.py:90}} INFO - Filling up the DagBag from /usr/local/airflow/dags/store_DAG.py
[2020-08-04 20:46:39,485] {{base_task_runner.py:115}} time Job 22: Subtask check_file_exists [2020-08-04 20:46:39,484] {{cli.py:516}} INFO - Running <TaskInstance: store_DAG.check_file_exists 2020-07-29T00:00:00+00:00 [running]> on host 46a88ec199b8
[2020-08-04 20:46:39,752] {{bash_operator.py:81}} time Tmp dir root location: 
 /tmp
[2020-08-04 20:46:39,753] {{bash_operator.py:91}} time Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=store_DAG
AIRFLOW_CTX_TASK_ID=check_file_exists
AIRFLOW_CTX_EXECUTION_DATE=2020-07-29T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-07-29T00:00:00+00:00
[2020-08-04 20:46:39,756] {{bash_operator.py:105}} time Temporary script location: /tmp/airflowtmpee8bdvtq/check_file_existsm7h952po
[2020-08-04 20:46:39,762] {{bash_operator.py:115}} time Running command: shasum ~/store_files_airflow/raw_store_transactions.csv
[2020-08-04 20:46:39,897] {{bash_operator.py:124}} time Output:
[2020-08-04 20:46:40,406] {{bash_operator.py:128}} time e9e298e9629d72f3255b4838ba07bd220150a146  /usr/local/airflow/store_files_airflow/raw_store_transactions.csv
[2020-08-04 20:46:40,409] {{bash_operator.py:132}} time Command exited with return code 0
[2020-08-04 20:46:41,511] {{logging_mixin.py:95}} time [[34m2020-08-04 20:46:41,511[0m] {{[34mlocal_task_job.py:[0m172}} WARNING[0m - State of this instance has been externally set to [1msuccess[0m. Taking the poison pill.[0m
[2020-08-04 20:46:41,572] {{helpers.py:319}} time Sending Signals.SIGTERM to GPID 1634
[2020-08-04 20:46:41,868] {{helpers.py:297}} time Process psutil.Process(pid=1634, status='terminated') (1634) terminated with exit code -15
[2020-08-04 20:46:41,871] {{logging_mixin.py:95}} time [[34m2020-08-04 20:46:41,869[0m] {{[34mlocal_task_job.py:[0m105}} INFO[0m - Task exited with return code 0[0m
Dependencies all met for <TaskInstance: store_DAG.check_file_exists 2020-07-29T00:00:00+00:00 [queued]>
Dependencies all met for <TaskInstance: store_DAG.check_file_exists 2020-07-29T00:00:00+00:00 [queued]>

--------------------------------------------------------------------------------
Starting attempt 1 of 3

--------------------------------------------------------------------------------
Executing <Task(BashOperator): check_file_exists> on 2020-07-29T00:00:00+00:00
Running: ['airflow', 'run', 'store_DAG', 'check_file_exists', '2020-07-29T00:00:00+00:00', '--job_id', '16', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/store_DAG.py', '--cfg_path', '/tmp/tmp3dxuybfr']
Job 16: Subtask check_file_exists [2020-08-04 20:52:23,870] {{settings.py:213}} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=1444
Job 16: Subtask check_file_exists /usr/local/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
Job 16: Subtask check_file_exists   """)
Job 16: Subtask check_file_exists [2020-08-04 20:52:25,326] {{__init__.py:51}} INFO - Using executor LocalExecutor
Job 16: Subtask check_file_exists [2020-08-04 20:52:30,628] {{dagbag.py:90}} INFO - Filling up the DagBag from /usr/local/airflow/dags/store_DAG.py
Job 16: Subtask check_file_exists [2020-08-04 20:52:31,317] {{cli.py:516}} INFO - Running <TaskInstance: store_DAG.check_file_exists 2020-07-29T00:00:00+00:00 [running]> on host 6a822f9627d0
Tmp dir root location: 
 /tmp
Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=store_DAG
AIRFLOW_CTX_TASK_ID=check_file_exists
AIRFLOW_CTX_EXECUTION_DATE=2020-07-29T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-07-29T00:00:00+00:00
Temporary script location: /tmp/airflowtmpcy3vrg8f/check_file_existslzq02ztp
Running command: shasum ~/store_files_airflow/raw_store_transactions.csv
Output:
e9e298e9629d72f3255b4838ba07bd220150a146  /usr/local/airflow/store_files_airflow/raw_store_transactions.csv
Command exited with return code 0
[[34m2020-08-04 20:52:33,548[0m] {{[34mlocal_task_job.py:[0m172}} WARNING[0m - State of this instance has been externally set to [1msuccess[0m. Taking the poison pill.[0m
Sending Signals.SIGTERM to GPID 1444
Process psutil.Process(pid=1444, status='terminated') (1444) terminated with exit code -15
[[34m2020-08-04 20:52:34,127[0m] {{[34mlocal_task_job.py:[0m105}} INFO[0m - Task exited with return code 0[0m
message ----> Dependencies all met for <TaskInstance: store_DAG.check_file_exists 2020-07-29T00:00:00+00:00 [queued]>
message ----> Dependencies all met for <TaskInstance: store_DAG.check_file_exists 2020-07-29T00:00:00+00:00 [queued]>
message ----> 
--------------------------------------------------------------------------------
message ----> Starting attempt 1 of 3
message ----> 
--------------------------------------------------------------------------------
message ----> Executing <Task(BashOperator): check_file_exists> on 2020-07-29T00:00:00+00:00
message ----> Running: ['airflow', 'run', 'store_DAG', 'check_file_exists', '2020-07-29T00:00:00+00:00', '--job_id', '16', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/store_DAG.py', '--cfg_path', '/tmp/tmpnpb1yhuc']
message ----> Job 16: Subtask check_file_exists [2020-08-04 21:10:16,077] {{settings.py:213}} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=1894
message ----> Job 16: Subtask check_file_exists /usr/local/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
message ----> Job 16: Subtask check_file_exists   """)
message ----> Job 16: Subtask check_file_exists [2020-08-04 21:10:17,208] {{__init__.py:51}} INFO - Using executor LocalExecutor
message ----> Job 16: Subtask check_file_exists [2020-08-04 21:10:22,237] {{dagbag.py:90}} INFO - Filling up the DagBag from /usr/local/airflow/dags/store_DAG.py
message ----> Job 16: Subtask check_file_exists [2020-08-04 21:10:22,648] {{cli.py:516}} INFO - Running <TaskInstance: store_DAG.check_file_exists 2020-07-29T00:00:00+00:00 [running]> on host 0885e5a330eb
message ----> Tmp dir root location: 
 /tmp
message ----> Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=store_DAG
AIRFLOW_CTX_TASK_ID=check_file_exists
AIRFLOW_CTX_EXECUTION_DATE=2020-07-29T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-07-29T00:00:00+00:00
message ----> Temporary script location: /tmp/airflowtmpst545h_q/check_file_exists71ymaz0t
message ----> Running command: shasum ~/store_files_airflow/raw_store_transactions.csv
message ----> Output:
message ----> e9e298e9629d72f3255b4838ba07bd220150a146  /usr/local/airflow/store_files_airflow/raw_store_transactions.csv
message ----> Command exited with return code 0
message ----> [[34m2020-08-04 21:10:26,879[0m] {{[34mlocal_task_job.py:[0m105}} INFO[0m - Task exited with return code 0[0m
